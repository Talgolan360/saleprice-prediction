# -*- coding: utf-8 -*-
"""Dataset and partial code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fgTzgxOv1gcoraFOTsjk47IwEDNT1FQW

# Dataset and partial code from https://www.kaggle.com/code/ayrgthonsoraca/saleprice-prediction-tf-rf-regressor
# Search for data explanation in link above
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



"""# Preprocessing"""

from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

def preprocess_data(df, is_train=True):
    processed_df = df.copy()

    if is_train:
        processed_df = processed_df[processed_df["SalePrice"] < 350000]
        processed_df = processed_df[processed_df["SalePrice"] < 350000]
        processed_df = processed_df[processed_df["GarageArea"]  <= 1000 ]
        processed_df = processed_df[processed_df["TotalBsmtSF"]  <= 3000 ]
        processed_df = processed_df[processed_df["GrLivArea"]  <= 3000 ]
        processed_df = processed_df[processed_df["LotArea"]  <= 50000 ]

    # Apply preprocessing steps
    processed_df = processed_df.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage', 'Id'], axis=1)
    processed_df["GarageVolume"] = processed_df["GarageCars"] * processed_df["GarageArea"]
    processed_df["GarageAreaRatio"] = processed_df["GarageArea"] / processed_df["GrLivArea"]
    processed_df.replace({"ExterQual": {"Ex": 4, "Gd": 3, "TA": 2, "Fa": 1}}, inplace=True)
    processed_df["OverallQual"] = processed_df["OverallQual"] / processed_df["OverallQual"].max()
    processed_df["ExterQual"] = (processed_df["ExterQual"] - processed_df["ExterQual"].min()) / (processed_df["ExterQual"].max() - processed_df["ExterQual"].min())
    processed_df["TotalQuall"] = (processed_df["OverallQual"] + processed_df["ExterQual"]) / 2
    processed_df.replace({"HeatingQC": {"Ex": 4, "Gd": 3, "TA": 2, "Fa": 1, "Po" : 0}}, inplace=True)
    processed_df.replace({"GarageQual": {"Ex": 4, "Gd": 3, "TA": 2, "Fa": 1, "Po" : 0}}, inplace=True)
    processed_df.replace({"KitchenQual": {"Ex": 4, "Gd": 3, "TA": 2, "Fa": 1}}, inplace=True)
    processed_df.replace({"CentralAir": {"Y" : 1, "N" : 0}}, inplace=True)

    categorical_cols = processed_df.select_dtypes(include=['object']).columns
    label_encoder = LabelEncoder()
    processed_df[categorical_cols] = processed_df[categorical_cols].apply(label_encoder.fit_transform)

    numeric_cols = processed_df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='median')
    processed_df[numeric_cols] = imputer.fit_transform(processed_df[numeric_cols])

    return processed_df

data = pd.read_csv("train.csv")
processed_train = preprocess_data(data, is_train = True)
label = 'SalePrice'

processed_train.info()

processed_train.head()

"""# NEW DATA"""

from sklearn.model_selection import train_test_split
from sklearn import linear_model ##זה הספריה שעושה ריגרסיה ליניאראית
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error #כל המטריקות

train, test = train_test_split(processed_train, test_size=0.3, random_state=42)

processed_train.columns

# Build X (feature table) and y (target) using corresponding columns
#נבנה את הטבלאות
X_train = train [['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',
       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',
       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',
       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',
       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',
       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',
       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',
       'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',
       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',
       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',
       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',
       'MoSold', 'YrSold', 'SaleType', 'SaleCondition',
       'GarageVolume', 'GarageAreaRatio', 'TotalQuall']]
y_train = train [ 'SalePrice']
# במידה ואין רווחים בשם אפשר לכתוב גם ככה:
#y_train = train.median_house_value
X_test = test [['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',
       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',
       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',
       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',
       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',
       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',
       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',
       'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',
       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',
       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',
       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',
       'MoSold', 'YrSold', 'SaleType', 'SaleCondition',
       'GarageVolume', 'GarageAreaRatio', 'TotalQuall']]
y_test = test [ 'SalePrice']

from sklearn import linear_model ##זה הספריה שעושה ריגרסיה ליניאראית
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error #כל המטריקות

from sklearn.model_selection import GridSearchCV

data_copy=processed_train.copy()

reg_model=LinearRegression()

param_grid = {
    'fit_intercept': [True, False],
    'copy_X': [True, False]
}

grid_search = GridSearchCV(reg_model, param_grid, cv=5)

best_grid=grid_search.fit(X_train, y_train)  # dont show,becuase he chose the default parameters(true)

best_grid.best_estimator_

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

# Print the best model and its parameters
print("Best Model:", best_model)
print("Best Parameters:", best_params)

y_predict =best_model.predict(X_test) #עושה את התחזית

import numpy as np
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100
# Assuming you have already performed GridSearchCV and obtained the best model
best_model = grid_search.best_estimator_

# Obtain predictions from the best model
# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test, y_predict))

# Calculate R-squared
r2 = r2_score(y_test, y_predict)

# Calculate MAE
mae = mean_absolute_error(y_test, y_predict)

# Calculate MAPE
mape = mean_absolute_percentage_error(y_test, y_predict)
print("RMSE:", rmse)
print("R-squared:", r2)
print("MAE:", mae)
print("MAPE:", mape)

"""We chose the parameter "MAPE" becuse he use percantage and dont create big gaps between parameters"""

new_data = pd.read_csv("test.csv")
processed_new_data = preprocess_data(new_data, is_train = False)

data_copy_test=processed_new_data.copy()

pred_test=best_grid.predict(data_copy_test)

pred_test

"""**we choose XGBRegressor**"""

import xgboost as xgb

params = {
    'learning_rate': [0.01, 0.1],
    'n_estimators': [100, 200],
    'max_depth': [3, 5],
    'subsample': [0.8],
    'colsample_bytree': [0.8],
    'min_child_weight': [1, 3 ]
}

xgb_model =xgb.XGBRegressor()

grid_Xsearch = GridSearchCV(xgb_model, params, cv=5)

grid_Xsearch.fit(X_train, y_train)

best_Xmodel =grid_Xsearch.best_estimator_
best_Xparams = grid_Xsearch.best_params_

# Print the best model and its parameters
print("Best Parameters:", best_Xparams)

y_pred_XG = best_Xmodel.predict(X_test)

y_pred_XG_train = best_Xmodel.predict(X_train)

import numpy as np
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100
# Assuming you have already performed GridSearchCV and obtained the best model

# Obtain predictions from the best model
# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_test ,y_pred_XG ))

# Calculate R-squared
r2 = r2_score(y_test ,y_pred_XG )

# Calculate MAE
mae = mean_absolute_error(y_test ,y_pred_XG  )

# Calculate MAPE TRAIN
mape = mean_absolute_percentage_error(y_train ,y_pred_XG_train)
# Calculate MAPE Test
mape1 = mean_absolute_percentage_error(y_test ,y_pred_XG)
print("RMSE:", rmse)
print("R-squared:", r2)
print("MAE:", mae)
print("MAPE_train:", mape)
print("MAPE_test:", mape1)

"""**We checked whether there is an overfiting between the training and the test, We saw that both are of the same order of magnitude. Therefore there is no overfiting**

**According to MAPE results
MAPA linear regression output 9.27676188791655
MAPE XGBOOST released 8.474942166770974
So the better model is XGBOOST**

# **NEW DATA**
"""

new_data = pd.read_csv("test.csv")
processed_new_data = preprocess_data(new_data, is_train = False)

processed_new_data.head()

predicted_newDATA=best_Xmodel.predict(processed_new_data)

predicted_newDATA

processed_train["target_clas"]=0
for item in processed_train.index:
  if processed_train.loc[item,"SalePrice"] <=250000:
    processed_train.loc[item,"target_clas"]=0
  else :
    processed_train.loc[item,"target_clas"]=1

processed_train.head()

processed_train.drop(["SalePrice"],axis=1)

# Split data  into train and test
# the parameter test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%
train, test = train_test_split(processed_train, test_size = 0.3, random_state = 0,stratify=processed_train['target_clas'])
print(train.shape)
print(test.shape)

# Build X (feature table) and y (target) using corresponding columns
#נבנה את הטבלאות
X_train_clas = train [['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',
       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',
       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',
       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',
       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',
       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',
       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',
       'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',
       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',
       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',
       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',
       'MoSold', 'YrSold', 'SaleType', 'SaleCondition',
       'GarageVolume', 'GarageAreaRatio', 'TotalQuall']]
y_train_clas = train [ 'target_clas']
# במידה ואין רווחים בשם אפשר לכתוב גם ככה:
#y_train = train.median_house_value
X_test_clas = test [['MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',
       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',
       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',
       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',
       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',
       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',
       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',
       'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',
       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',
       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',
       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',
       'MoSold', 'YrSold', 'SaleType', 'SaleCondition',
       'GarageVolume', 'GarageAreaRatio', 'TotalQuall']]
y_test_clas = test [ 'target_clas']

"""# **we choos Decision Tree Classifier**"""

from sklearn.tree import DecisionTreeClassifier # import Decision Tree Classifier model
# Include confusion matrix plot function to be used when we have defined a classifir (model) as we have (model with KNN)
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_auc_score
import warnings # current version of seaborn generates a bunch of warnings that we'll ignore
warnings.filterwarnings("ignore")

tree_clf = DecisionTreeClassifier(random_state=0)

# Train the classifier using Train data
tree_clf.fit(X_train_clas,y_train_clas)

#In the cmd line type: conda install python-graphviz
from sklearn.tree import export_graphviz
import graphviz

#In the cmd line type: conda install -c conda-forge pydotplus
import pydotplus # conda install -c conda-forge pydotplus

dot_data = export_graphviz(tree_clf, out_file = None,
                           feature_names = X_train_clas.columns,
                           class_names = ["0", "1" ],


                           rounded = True, filled=True, special_characters=True)
graph1 = graphviz.Source(dot_data)

# save image to show below in markdown
pydot_graph = pydotplus.graph_from_dot_data(dot_data)
pydot_graph.write_png('tree_clf.png')
#show the full graph
graph1

from sklearn.model_selection import GridSearchCV

param_grid_Tree = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']
}

dt_classifier = DecisionTreeClassifier()

grid_search_TREE = GridSearchCV(dt_classifier, param_grid_Tree, cv=5)

grid_search_TREE.fit(X_train_clas, y_train_clas)

best_model_TREE = grid_search_TREE.best_estimator_
best_params_TREE = grid_search_TREE.best_params_

print(best_model_TREE )
print(best_params_TREE )

y_pred_tree = best_model_TREE.predict(X_test_clas)

"""**Q.13**"""

num_combinations = len(grid_search_TREE.cv_results_['params'])
print("Number of combinations calculated:", num_combinations)

#In the cmd line type: conda install python-graphviz
from sklearn.tree import export_graphviz
import graphviz

#In the cmd line type: conda install -c conda-forge pydotplus
import pydotplus # conda install -c conda-forge pydotplus

dot_data1 = export_graphviz(best_model_TREE , out_file = None,
                           feature_names = X_train_clas.columns,
                           class_names = ["0", "1" ],


                           rounded = True, filled=True, special_characters=True)
graph2 = graphviz.Source(dot_data1 )

# save image to show below in markdown
pydot_graph1 = pydotplus.graph_from_dot_data(dot_data1)
pydot_graph1.write_png('tree_clf1.png')
#show the full graph
graph2

"""**Q.14**"""

# Show confusion matrix
ConfusionMatrixDisplay.from_predictions(y_test_clas, y_pred_tree)

# Calculate metrics
# Accuracy using scikit-learn
print("Measurement for Test data:")
from sklearn.metrics import accuracy_score
print("Accuracy: ", accuracy_score(y_test_clas, y_pred_tree))

# Recall
from sklearn.metrics import recall_score
print("Recall: ", recall_score(y_test_clas, y_pred_tree))

# Precision
from sklearn.metrics import precision_score
print("Precision: ", precision_score(y_test_clas, y_pred_tree))

# F1 score
from sklearn.metrics import f1_score
f1 = f1_score(y_test_clas, y_pred_tree)
print("F1 score: ", f1)

# Make predictions for test data using trained model
predicted_train_yClas = tree_clf.predict(X_train_clas)

#Show confusion matrix for Train data predictions
ConfusionMatrixDisplay.from_predictions(y_train_clas,predicted_train_yClas)

# Calculate metrics
# Accuracy using scikit-learn
print("Measurement for Train data:")
from sklearn.metrics import accuracy_score
print("Accuracy: ", accuracy_score(y_train_clas,predicted_train_yClas))

# Recall
from sklearn.metrics import recall_score
print("Recall: ", recall_score(y_train_clas,predicted_train_yClas))

# Precision
from sklearn.metrics import precision_score
print("Precision: ", precision_score(y_train_clas,predicted_train_yClas))

# F1 score
from sklearn.metrics import f1_score
f1 = f1_score(y_train_clas,predicted_train_yClas)
print("F1 score: ", f1)

"""Metrics for training data are better than metrics for test data - Over Fitting
We need to inprove our model performance

We will try max depth of tree:

"""

# Build new classifier setting max depth of tree to 3
max_depth_tree_clf = DecisionTreeClassifier(random_state=0,max_depth=3)

# Train the new classifier with Train data
max_depth_tree_clf.fit(X_train_clas, y_train_clas)

# Make predictions using new model over test data
predicted_y = max_depth_tree_clf.predict(X_test_clas)

# Plot consufion matrix
ConfusionMatrixDisplay.from_predictions(y_test_clas,predicted_y)

# Calculate metrics
# Accuracy using scikit-learn
print("Measurement for Test data:")
from sklearn.metrics import accuracy_score
print("Accuracy: ", accuracy_score(y_test_clas,predicted_y))

# Recall
from sklearn.metrics import recall_score
print("Recall: ", recall_score(y_test_clas,predicted_y))

# Precision
from sklearn.metrics import precision_score
print("Precision: ", precision_score(y_test_clas,predicted_y))

# F1 score
from sklearn.metrics import f1_score
f1 = f1_score(y_test_clas,predicted_y)
print("F1 score: ", f1)

# Make predictions using new model over Train data
predicted_train_yMAX = max_depth_tree_clf.predict(X_train_clas)
#plot_confusion_matrix(max_depth_tree_clf,train_X,train_y)
print("Measurement for Train data:")
# Accuracy using SKLEARN
from sklearn.metrics import accuracy_score
print("Accuracy: ",accuracy_score(y_train_clas, predicted_train_yMAX))

# Recall
from sklearn.metrics import recall_score
print("Recall: ",recall_score(y_train_clas, predicted_train_yMAX))

# Precision
from sklearn.metrics import precision_score
print("Precision: ",precision_score(y_train_clas, predicted_train_yMAX))

# F1 score
from sklearn.metrics import f1_score
f1 = f1_score(y_train_clas, predicted_train_yMAX)
print("F1 score: ", f1)

"""We managed to reduce the overfitting

"""

# Display decision tree with max_depth = 3
dot_data3 = export_graphviz(max_depth_tree_clf, out_file = None,
                           feature_names = X_train_clas.columns,
                           class_names = ["0", "1" ],
                           rounded = True, filled=True, special_characters=True)
graph3 = graphviz.Source(dot_data3)

# save image to show below in markdown
pydot_graph = pydotplus.graph_from_dot_data(dot_data3)
pydot_graph.write_png('max_depth_tree_clf.png')
#show the full graph
graph3

# Build model using Entropy criterion
entropy_clf = DecisionTreeClassifier(random_state=0,criterion = 'entropy',max_depth=4)

# train model
entropy_clf.fit(X_train_clas, y_train_clas)

# Make predictions
predicted_yENT = entropy_clf.predict(X_test_clas)

# Show confusion matrix for test dta
ConfusionMatrixDisplay.from_predictions(y_test_clas,predicted_yENT)

print("Measurement for Test data:")
# Show metrics for test data
# Accuracy using SKLEARN
from sklearn.metrics import accuracy_score
print("Accuracy: ",accuracy_score(y_test_clas,predicted_yENT))

# Recall
from sklearn.metrics import recall_score
print("Recall: ",recall_score(y_test_clas,predicted_yENT))

# Precision
from sklearn.metrics import precision_score
print("Precision: ",precision_score(y_test_clas,predicted_yENT))

"""**Q.15**"""

import matplotlib.pyplot as plt
import numpy as np

importances = entropy_clf.feature_importances_

feature_names = X_train_clas.columns

indices = np.argsort(importances)[::-1]
sorted_importances = importances[indices]
sorted_feature_names = feature_names[indices]

plt.figure(figsize=(10, 6))
plt.barh(range(len(sorted_importances)), sorted_importances, align='center')
plt.yticks(range(len(sorted_importances)), sorted_feature_names)
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Decision Tree Classifier - Feature Importances')
plt.show()

"""Because we have a lot of features we will display the top 10

"""

top_n = 10  # Specify the number of top features to display
sorted_importances = importances[indices[:top_n]]
sorted_feature_names = feature_names[indices[:top_n]]

sorted_feature_names

plt.yticks(range(top_n), sorted_feature_names)

import matplotlib.pyplot as plt
import numpy as np

# Get the feature importances from your decision tree classifier
importances = entropy_clf.feature_importances_

# Get the corresponding feature names
feature_names = X_train_clas.columns

# Sort the feature importances and feature names in descending order
indices = np.argsort(importances)[::-1]
top_n = 10  # Specify the number of top features to display
sorted_importances = importances[indices[:top_n]]
sorted_feature_names = feature_names[indices[:top_n]]

# Create a horizontal bar plot to visualize the feature importances
plt.figure(figsize=(10, 6))
plt.barh(range(len(sorted_importances)), sorted_importances, align='center')
plt.yticks(range(top_n), sorted_feature_names)
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Decision Tree Classifier - Top 10 Feature Importances')
plt.show()

reduced_matrix = X_test_clas [ ['OverallQual', 'GrLivArea', 'BsmtFinSF1', 'TotalQuall', 'TotalBsmtSF',
       'KitchenQual', 'MoSold', 'YearBuilt', 'YrSold', 'ExterCond']]
reduced_matrix [ 'target_clas' ] = y_test_clas

# Display correlation map with a more useful layout
# Increase the size of the heatmap.
plt.figure(figsize=(16, 6))
# Store heatmap object in a variable to easily access it when you want to include more features (such as title).
# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.
heatmap = sns.heatmap(reduced_matrix.corr(), vmin=-1, vmax=1, annot=True,cmap='BrBG')
# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.
heatmap.set_title('Most Important Features - Correlation Heatmap', fontdict={'fontsize':12}, pad=12);

train_X_reduced = X_train_clas [['OverallQual', 'GrLivArea', 'BsmtFinSF1', 'TotalQuall', 'TotalBsmtSF',
       'KitchenQual', 'MoSold', 'YearBuilt', 'YrSold', 'ExterCond']]
test_X_reduced = X_test_clas [['OverallQual', 'GrLivArea', 'BsmtFinSF1', 'TotalQuall', 'TotalBsmtSF',
       'KitchenQual', 'MoSold', 'YearBuilt', 'YrSold', 'ExterCond']]

# Build model using Entropy criterion
entropy_clf_reduced = DecisionTreeClassifier(random_state=0,criterion = 'entropy',max_depth=3)

# train model
entropy_clf_reduced.fit(train_X_reduced,y_train_clas)

# Make predictions
predicted_y_reduced = entropy_clf_reduced.predict(test_X_reduced)

print("Measurement for Test data:")
# Show metrics for test data
# Accuracy using SKLEARN
from sklearn.metrics import accuracy_score
print("Accuracy: ",accuracy_score(y_test_clas, predicted_y_reduced))

# Recall
from sklearn.metrics import recall_score
print("Recall: ",recall_score(y_test_clas, predicted_y_reduced))

# Precision
from sklearn.metrics import precision_score
print("Precision: ",precision_score(y_test_clas, predicted_y_reduced))

# Show confusion matrix for test dta
ConfusionMatrixDisplay.from_predictions(y_test_clas, predicted_y_reduced)

print()
print("Measurement for Train data:")
predicted_y_train_reduced = entropy_clf_reduced.predict(train_X_reduced)
# Show metrics for train data
# Accuracy using SKLEARN
from sklearn.metrics import accuracy_score
print("Accuracy: ",accuracy_score(y_train_clas, predicted_y_train_reduced))

# Recall
from sklearn.metrics import recall_score
print("Recall: ",recall_score(y_train_clas, predicted_y_train_reduced))

# Precision
from sklearn.metrics import precision_score
print("Precision: ",precision_score(y_train_clas, predicted_y_train_reduced))

# Show confusion matrix for train dta
ConfusionMatrixDisplay.from_predictions(y_train_clas,predicted_y_train_reduced)

"""**Q.16**

"""

#create array of probabilities
y_test_predict_proba = entropy_clf_reduced.predict_proba(test_X_reduced)
y_test_predict_proba

from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_true = y_test_clas, probas_pred = y_test_predict_proba[:,1])
print(" Precision = ", precisions, "\n", "Recalls = ", recalls, "\n", "Thresholds = ", thresholds)

def plot_precision_recall_vs_threshold (precisions, recalls, thresholds, color = "k", label = None):
    plt.plot (thresholds, precisions[:-1], color+"--", label="Precision -"+label)
    plt.plot (thresholds, recalls[:-1], color+"-", label="Recall -"+label)
    plt.xlabel("Threshold")
    plt.legend(loc="upper right")
    plt.ylim([0,1])

plot_precision_recall_vs_threshold( precisions, recalls, thresholds, color = "b", label="Entropy Reduced Tree")
plt.legend(loc = "best")
plt.show()

"""# Part 2:"""



milli_followers = [200004]
eden_followers = [195023]
noa_followers = [201100]
bar_followers = [87023]
agam_followers = [184245]
bella_followers = [120]

data1 = milli_followers
data2 = eden_followers + noa_followers + bar_followers + agam_followers + bella_followers
alpha = 0.05
num_iterations = 10000

import numpy as np

def bootstrap_hypothesis_test(data1, data2, alpha, num_iterations):
    observed_diff = np.mean(data1) - np.mean(data2)
    combined_data = np.concatenate((data1, data2))
    n1 = len(data1)
    n2 = len(data2)
    bootstrap_diffs = np.zeros(num_iterations)

    for i in range(num_iterations):
        bootstrap_sample1 = np.random.choice(combined_data, size=n1, replace=True)
        bootstrap_sample2 = np.random.choice(combined_data, size=n2, replace=True)
        bootstrap_diffs[i] = np.mean(bootstrap_sample1) - np.mean(bootstrap_sample2)

    p_value = np.sum(bootstrap_diffs >= observed_diff) / num_iterations

    return p_value, p_value < alpha

p_value, reject_null = bootstrap_hypothesis_test(data1, data2, alpha, num_iterations)

print("p-value:", p_value)
if reject_null:
    print("Milli's claim is supported at a 95% confidence level.")
else:
    print("Milli's claim is not supported at a 95% confidence level.")